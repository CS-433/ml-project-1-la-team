{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the best model and make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "# import self-defined modules\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "from src.helpers import *\n",
    "from src.implementations import *\n",
    "from src.cross_validation import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"./data/\"\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEST_FILE = \"test.csv\"\n",
    "\n",
    "RESULT_FOLDER = \"./results/\"\n",
    "RESULT_FILE = \"predictions.csv\"\n",
    "\n",
    "NAN_VALUE = -999.0\n",
    "INTEGER_COLUMN = (\n",
    "    22  # 24 in raw csv file, but 23 when id and prediction column are removed\n",
    ")\n",
    "\n",
    "# For debug purpose only\n",
    "SUB_SAMPLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_tr shape : (250000, 30), y_tr shape : (250000,)\n",
      "x_te shape : (568238, 30), y_te shape : (568238,)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "y_tr, x_tr, _ = load_csv_data(DATA_FOLDER + TRAIN_FILE, sub_sample=SUB_SAMPLE)\n",
    "y_te, x_te, ids_tests = load_csv_data(DATA_FOLDER + TEST_FILE, sub_sample=SUB_SAMPLE)\n",
    "print(\"x_tr shape : {}, y_tr shape : {}\".format(x_tr.shape, y_tr.shape))\n",
    "print(\"x_te shape : {}, y_te shape : {}\".format(x_te.shape, y_te.shape))\n",
    "\n",
    "# Define missing values as NAN\n",
    "x_tr[x_tr == NAN_VALUE] = np.nan\n",
    "x_te[x_te == NAN_VALUE] = np.nan\n",
    "\n",
    "# Get columns names\n",
    "col_names = []\n",
    "with open(DATA_FOLDER + TRAIN_FILE) as dataset:\n",
    "    col_names = dataset.readline().split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before pre-processing:\n",
      "x_tr shape : (250000, 30)\n",
      "x_te shape : (568238, 30)\n",
      "x_tr range :-18.066 4974.979\n",
      "x_te range :-19.012 4794.827\n"
     ]
    }
   ],
   "source": [
    "# before pre-processing\n",
    "print(\"Before pre-processing:\")\n",
    "print(\"x_tr shape : {}\".format(x_tr.shape))\n",
    "print(\"x_te shape : {}\".format(x_te.shape))\n",
    "print(\"x_tr range :{} {}\".format(np.nanmin(x_tr), np.nanmax(x_tr)))\n",
    "print(\"x_te range :{} {}\".format(np.nanmin(x_te), np.nanmax(x_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply log transformation\n",
    "cols_to_log_transform = [\"DER_pt_h\", \"DER_pt_tot\", \"PRI_met\", \"PRI_met_sumet\"]\n",
    "cols_idx = [get_col_idx(col, col_names) for col in cols_to_log_transform]\n",
    "\n",
    "x_tr, x_te = log_transform(x_tr, x_te, cols_idx)\n",
    "\n",
    "# Remove columns with too much NAN\n",
    "x_tr = remove_nan_columns(x_tr, 0.3)\n",
    "x_te = remove_nan_columns(x_te, 0.3)\n",
    "\n",
    "# Replace missing data by the mean\n",
    "mean_x = np.nanvar(x_tr, axis=0)\n",
    "x_tr = replace_nan_by_means(x_tr, mean_data=mean_x)\n",
    "x_te = replace_nan_by_means(x_te, mean_data=mean_x)\n",
    "\n",
    "\n",
    "assert x_tr[np.isnan(x_tr)].shape[0] == 0\n",
    "assert x_te[np.isnan(x_te)].shape[0] == 0\n",
    "\n",
    "# Standardize after replacing missing values\n",
    "IDs_degrees = np.array([10, 13, 15])\n",
    "x_tr = transform(x_tr, IDs_degrees)\n",
    "x_te = transform(x_te, IDs_degrees)\n",
    "\n",
    "# Polynomial feature expansion\n",
    "xt_tr = build_poly(x_tr, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pre-processing:\n",
      "x_tr shape : (250000, 23)\n",
      "x_te shape : (568238, 23)\n",
      "x_tr range :-2.0760373982511515 6.712827536317546\n",
      "x_te range :-2.0734828021024287 6.719471419278016\n"
     ]
    }
   ],
   "source": [
    "# plot features after pre-processing\n",
    "print(\"After pre-processing:\")\n",
    "print(\"x_tr shape : {}\".format(x_tr.shape))\n",
    "print(\"x_te shape : {}\".format(x_te.shape))\n",
    "print(\"x_tr range :{} {}\".format(np.min(x_tr), np.max(x_tr)))\n",
    "print(\"x_te range :{} {}\".format(np.min(x_te), np.max(x_te)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy : 0.814012\n",
      "Training f1       : 0.7159013839244799\n"
     ]
    }
   ],
   "source": [
    "w, loss = ridge_regression(y_tr, xt_tr, lambda_=0.0005)\n",
    "y_pred_tr = predict_reg(w, xt_tr)\n",
    "\n",
    "print(\"Training accuracy : {}\".format(accuracy(y_tr, y_pred_tr)))\n",
    "print(\"Training f1       : {}\".format(f1_score(y_tr, y_pred_tr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test value and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on the train set\n",
    "# 0.0001\t0.0\t6\t0.814147\t0.71644\n",
    "# 0.0005\t0.0\t6\n",
    "\n",
    "# Run on the test set\n",
    "xt_te = build_poly(x_te, 6)\n",
    "y_pred_te = predict_reg(w, xt_te)\n",
    "\n",
    "y_test, input_test, ids_test = load_csv_data(DATA_FOLDER + TEST_FILE, False)\n",
    "\n",
    "create_csv_submission(ids_test, y_pred_te, RESULT_FOLDER + RESULT_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d6cc526fcb8a0758310ed89b8dab3b91f3ec4de7507d09c9bf6f1d1fde12f3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
