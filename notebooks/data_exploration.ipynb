{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "# import self-defined modules\n",
    "sys.path.append('../')\n",
    "from implementations import *\n",
    "from helpers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../data/\"\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEST_FILE = \"test.csv\"\n",
    "IS_DEBUG = True\n",
    "NAN_VALUE = -999.0\n",
    "INTEGER_COLUMN = (\n",
    "    22  # 24 in raw csv file, but 23 when id and prediction column are removed\n",
    ")\n",
    "\n",
    "# For debug purpose only\n",
    "SUB_SAMPLE = False\n",
    "SHOW_GRAPHS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "y_tr,x_tr,_ = load_csv_data(\n",
    "    DATA_FOLDER + TRAIN_FILE, sub_sample=SUB_SAMPLE\n",
    ") \n",
    "y_te, x_te,ids_tests = load_csv_data(DATA_FOLDER + TEST_FILE, sub_sample=SUB_SAMPLE)\n",
    "print(\"x_tr shape : {}, y_tr shape : {}\".format(x_tr.shape, y_tr.shape))\n",
    "print(\"x_te shape : {}, y_te shape : {}\".format(x_te.shape, y_te.shape))\n",
    "\n",
    "# Define missing values as NAN\n",
    "x_tr[x_tr == NAN_VALUE] = np.nan\n",
    "x_te[x_te == NAN_VALUE] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_s = len(y_tr[y_tr == 1])\n",
    "nb_b = len(y_tr) - nb_s\n",
    "print(\"Signals: {} ({}%)\".format(nb_s, 100 * nb_s / len(x_tr)))\n",
    "print(\"Backgrounds: {} ({}%)\".format(nb_b, 100 * nb_b / len(x_tr)))\n",
    "print(\"Ratio signal / background: {}\".format(nb_s / nb_b))\n",
    "\n",
    "plt.bar([\"Signal\", \"Background\"], [nb_s, nb_b])\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Labels distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NAN_RATIO = 0.5\n",
    "\n",
    "nb_nan = np.count_nonzero(np.isnan(x_tr), axis=0)\n",
    "nan_ratio = nb_nan / x_tr.shape[1]\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Nb Columns with > {:.2f} nan ratio : {}\".format(\n",
    "        MAX_NAN_RATIO, np.count_nonzero(nan_ratio >= MAX_NAN_RATIO)\n",
    "    )\n",
    ")\n",
    "\n",
    "col_names = []\n",
    "with open(DATA_FOLDER + TRAIN_FILE) as dataset:\n",
    "    col_names = dataset.readline().split(\",\")\n",
    "    nan_col_names = [\n",
    "        col_name for col_idx, col_name in enumerate(col_names[2:]) if nan_ratio[col_idx]\n",
    "    ]\n",
    "\n",
    "    print(\"Columns with > {:.2f} nan ratio :\".format(MAX_NAN_RATIO))\n",
    "    print(nan_col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 6, sharex=False, sharey=False, figsize=(12, 6))\n",
    "\n",
    "fig.suptitle(\"Histograms of raw features (excluding NAN values)\")\n",
    "\n",
    "# don't select nan values\n",
    "for col_idx in range(len(col_names)-2):\n",
    "    subplt = axs[col_idx%5, math.floor(col_idx/5)]\n",
    "\n",
    "    col = x_tr[:, col_idx]\n",
    "    subplt.hist(col[~np.isnan(col)], bins=100)\n",
    "    subplt.set_title(col_names[col_idx+2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In depth feature analysis\n",
    "Select one feature at the beginning of the cell (col_name_to_plot). Then, run the cell above and the following ones to analyse this feature in details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_in_depth = True\n",
    "\n",
    "if is_in_depth:\n",
    "    # select the feature to plot\n",
    "    col_name_to_plot = 'DER_pt_h'\n",
    "    col_idx_to_plot = get_col_idx(col_name_to_plot, col_names)\n",
    "\n",
    "    col_to_plot = x_tr[:, col_idx_to_plot].copy()\n",
    "    print(col_to_plot.shape)\n",
    "\n",
    "    col_to_plot = np.delete(col_to_plot, (7343), axis=0)\n",
    "    print(col_to_plot.shape)\n",
    "\n",
    "    # col_to_plot = col_to_plot[~np.isnan(col_to_plot)]\n",
    "\n",
    "    # remove potential outliers\n",
    "    # col_to_plot = col_to_plot[col_to_plot < 1800]\n",
    "\n",
    "    # plot distribution\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    axs[0].hist(col_to_plot[~np.isnan(col_to_plot)], bins=100)\n",
    "    axs[0].set_title(col_name_to_plot)\n",
    "\n",
    "    col_nan = col_to_plot[~np.isnan(col_to_plot)]\n",
    "    axs[1].boxplot(col_to_plot[~np.isnan(col_to_plot)])\n",
    "    axs[1].set_title(col_name_to_plot)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(\"min: {}, max: {}\".format(col_to_plot.min(), col_to_plot.max()))\n",
    "    print(\"argmin: {}, argmax: {}\".format(col_to_plot.argmin(), col_to_plot.argmax()))\n",
    "\n",
    "    # Outlier : DER_pt_h : 7343, outlier2 = 68116\n",
    "    # DER_pt_tot : 7343 again\n",
    "    # PRI_met : 7343 again\n",
    "    # features_to_log_transform = ['DER_pt_h', 'DER_pt_tot', 'PRI_met', 'PRI_met_sumet]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_in_depth:\n",
    "    col_to_plot = x_tr[:, col_idx_to_plot].copy()\n",
    "\n",
    "    # clean\n",
    "    # col_to_plot = col_to_plot[~np.isnan(col_to_plot)]\n",
    "    # col_to_plot = col_to_plot[col_to_plot < 1000]\n",
    "\n",
    "    col_to_plot = np.log(col_to_plot+1)\n",
    "    # col_to_plot, _,_  = standardize_training(col_to_plot)\n",
    "\n",
    "    # plot distribution\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    axs[0].hist(col_to_plot[~np.isnan(col_to_plot)], bins=100)\n",
    "    axs[0].set_title(col_name_to_plot)\n",
    "\n",
    "    col_nan = col_to_plot[~np.isnan(col_to_plot)]\n",
    "    axs[1].boxplot(col_to_plot[~np.isnan(col_to_plot)])\n",
    "    axs[1].set_title(col_name_to_plot)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(\"min: {}, max: {}\".format(col_to_plot.min(), col_to_plot.max()))\n",
    "    print(\"argmin: {}, argmax: {}\".format(col_to_plot.argmin(), col_to_plot.argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if the feature follows a power law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if is_in_depth:\n",
    "#     array_cumulative=plt.hist(col_to_plot,bins=100,log=True,cumulative=-1,histtype='step')\n",
    "#     plt.title('Histogram of Population (cumulative)')\n",
    "#     plt.ylabel('# of cantons (in log scale)')\n",
    "#     plt.xlabel('population')\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.loglog(array_cumulative[1][1:],array_cumulative[0])\n",
    "#     plt.title('Histogram of Population (cumulative)')\n",
    "#     plt.ylabel('# of cantons (in log scale)')\n",
    "#     plt.xlabel('population (in log scale)')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problematic features analysis\n",
    "Some features have been empricially defined as problematic. The problem is that after standardization, those features values will highly differ between the training and the test set, due the the presence of an outliers.\n",
    "The histograms and statistics below allows us to understand which features are problematic.  \n",
    "Using this technique, the sample 7343 has been identified as an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 6, sharex=False, sharey=False, figsize=(12, 6))\n",
    "\n",
    "fig.suptitle(\"Histograms of train features\")\n",
    "\n",
    "# don't select nan values\n",
    "for col_idx in range(x_tr.shape[1]):\n",
    "    subplt = axs[col_idx%5, math.floor(col_idx/5)]\n",
    "\n",
    "    col = x_tr[:, col_idx]\n",
    "    subplt.hist(col[~np.isnan(col)], bins=100)\n",
    "    subplt.set_title(col_names[col_idx+2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(5, 6, sharex=False, sharey=False, figsize=(12, 6))\n",
    "\n",
    "fig.suptitle(\"Histograms of test features\")\n",
    "\n",
    "# don't select nan values\n",
    "for col_idx in range(x_tr.shape[1]):\n",
    "    subplt = axs[col_idx%5, math.floor(col_idx/5)]\n",
    "\n",
    "    col = x_te[:, col_idx]\n",
    "    subplt.hist(col[~np.isnan(col)], bins=100)\n",
    "    subplt.set_title(col_names[col_idx+2])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_features = 'DER_mass_MMC', 'DER_mass_vis', 'DER_deltaeta_jet_jet', 'DER_prodeta_jet_jet', 'PRI_tau_eta'\n",
    "\n",
    "for col_name in problematic_features:\n",
    "    col_idx = get_col_idx(col_name, col_names)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "    # plot train distribution\n",
    "    col_tr = x_tr[:, col_idx].copy()\n",
    "    col_tr = col_tr[~np.isnan(col_tr)]\n",
    "\n",
    "    axs[0].hist(col_tr, bins=100)\n",
    "    axs[0].set_title(\"Train {}\".format(col_name))\n",
    "\n",
    "    # plot test distribution\n",
    "    col_te = x_te[:, col_idx].copy()\n",
    "    col_te = col_te[~np.isnan(col_te)]\n",
    "\n",
    "    axs[1].hist(col_te, bins=100)\n",
    "    axs[1].set_title(\"Test {}\".format(col_name))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # basic stats\n",
    "    print(\"Train:\")\n",
    "    print(\"min: {}, max: {}\".format(col_tr.min(), col_tr.max()))\n",
    "    print(\"argmin: {}, argmax: {}\".format(col_tr.argmin(), col_tr.argmax()))\n",
    "\n",
    "    print(\"Test:\")\n",
    "    print(\"min: {}, max: {}\".format(col_te.min(), col_te.max()))\n",
    "    print(\"argmin: {}, argmax: {}\".format(col_te.argmin(), col_te.argmax()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering / Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detected_outliers = [7343]\n",
    "\n",
    "\n",
    "# print(x_tr.shape)\n",
    "\n",
    "# for sample_row in detected_outliers:\n",
    "#     x_tr = np.delete(x_tr, (sample_row), axis=0)\n",
    "#     y_tr = np.delete(y_tr, (sample_row), axis=0)\n",
    "\n",
    "# print(x_tr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial range of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_tr range :{} {}\".format(np.nanmin(x_tr), np.nanmax(x_tr)))\n",
    "print(\"x_te range :{} {}\".format(np.nanmin(x_te), np.nanmax(x_te)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logarithmic feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : add a function to remove outliers\n",
    "xtr = x_tr.copy()\n",
    "xte = x_te.copy()\n",
    "\n",
    "cols_to_log_transform = ['DER_pt_h', 'DER_pt_tot', 'PRI_met', 'PRI_met_sumet']\n",
    "cols_idx = [get_col_idx(col, col_names) for col in cols_to_log_transform]\n",
    "\n",
    "xtr, xte = log_transform(xtr, xte, cols_idx)\n",
    "\n",
    "# Plot transformation\n",
    "for col_name in cols_to_log_transform:\n",
    "    col_idx = get_col_idx(col_name, col_names)\n",
    "    col_to_plot = xtr[:, col_idx]\n",
    "\n",
    "    #  plot distribution\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    axs[0].hist(col_to_plot[~np.isnan(col_to_plot)], bins=20)\n",
    "    axs[0].set_title(col_name)\n",
    "\n",
    "    axs[1].boxplot(col_to_plot[~np.isnan(col_to_plot)])\n",
    "    axs[1].set_title(col_name)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate final pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot features before preprocessing\n",
    "print(\"Before transformation:\")\n",
    "print(\"x_tr shape : {}\".format(x_tr.shape))\n",
    "print(\"x_te shape : {}\".format(x_te.shape))\n",
    "print(\"x_tr range :{} {}\".format(np.nanmin(x_tr), np.nanmax(x_tr)))\n",
    "print(\"x_te range :{} {}\".format(np.nanmin(x_te), np.nanmax(x_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with too much NAN\n",
    "nb_nan = np.count_nonzero(np.isnan(x_tr), axis=0)\n",
    "nan_ratio = nb_nan / x_tr.shape[1]\n",
    "\n",
    "max_nan_ratio = 0.5\n",
    "x_tr = x_tr[:, nan_ratio <= max_nan_ratio]\n",
    "x_te = x_te[:, nan_ratio <= max_nan_ratio]\n",
    "\n",
    "mean_x = np.nanmean(x_tr, axis=0)\n",
    "# Replace missing data by the mean\n",
    "x_tr = replace_nan_by_means(x_tr, mean_data=mean_x)\n",
    "x_te = replace_nan_by_means(x_te, mean_data=mean_x)\n",
    "\n",
    "assert(x_tr[np.isnan(x_tr)].shape[0] == 0)\n",
    "assert(x_te[np.isnan(x_te)].shape[0] == 0)\n",
    "\n",
    "# Standardize after replacing missing values\n",
    "IDs_degrees = np.array([10,13,15])\n",
    "x_tr = transform(x_tr,IDs_degrees)\n",
    "x_te = transform(x_te,IDs_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot features after pre-processing\n",
    "fig, axs = plt.subplots(5, 6, sharex=False, sharey=False, figsize=(12, 6))\n",
    "\n",
    "fig.suptitle(\"Histograms of train features\")\n",
    "\n",
    "# don't select nan values\n",
    "for col_idx in range(x_tr.shape[1]):\n",
    "    subplt = axs[col_idx%5, math.floor(col_idx/5)]\n",
    "\n",
    "    col = x_tr[:, col_idx]\n",
    "    subplt.hist(col[~np.isnan(col)], bins=100)\n",
    "    subplt.set_title(col_idx)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"After pre-processing:\")\n",
    "print(\"x_tr shape : {}\".format(x_tr.shape))\n",
    "print(\"x_te shape : {}\".format(x_te.shape))\n",
    "print(\"x_tr range :{} {}\".format(np.nanmin(x_tr), np.nanmax(x_tr)))\n",
    "print(\"x_te range :{} {}\".format(np.nanmin(x_te), np.nanmax(x_te)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b7477865c3b10d64ced3258d391994d31c5d5216fb1f6f71b5cb53c89252681"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
