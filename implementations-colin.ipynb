{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"./src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import *\n",
    "from helpers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = './data/'\n",
    "TRAIN_FILE = './train.csv'\n",
    "TEST_FILE = './test.csv'\n",
    "\n",
    "NAN_VALUE = -999.0\n",
    "INTEGER_COLUMN = 22 # 24 in raw csv file, but 23 when id and prediction column are removed\n",
    "\n",
    "# For debug purpose only\n",
    "SUB_SAMPLE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "x_tr, y_tr = load_data(DATA_FOLDER + TRAIN_FILE, sub_sample=SUB_SAMPLE)\n",
    "x_te, y_te = load_data(DATA_FOLDER + TEST_FILE, sub_sample=SUB_SAMPLE)\n",
    "\n",
    "print(\"x_tr shape : {}, y_tr shape : {}\".format(x_tr.shape, y_tr.shape))\n",
    "print(\"x_te shape : {}, y_te shape : {}\".format(x_te.shape, y_te.shape))\n",
    "\n",
    "# Define missing values as NAN\n",
    "x_tr[x_tr == NAN_VALUE] = np.nan\n",
    "x_te[x_te == NAN_VALUE] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features with too much NAN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NAN_RATIO = 0.5\n",
    "\n",
    "nb_nan = np.count_nonzero(np.isnan(x_tr), axis=0)\n",
    "nan_ratio = nb_nan / x_tr.shape[1]\n",
    "\n",
    "\n",
    "print(\"Nb Columns with > {:.2f} nan ratio : {}\".format(MAX_NAN_RATIO, np.count_nonzero(nan_ratio >= MAX_NAN_RATIO)))\n",
    "\n",
    "col_names = []\n",
    "with open(DATA_FOLDER + TRAIN_FILE) as dataset:\n",
    "    col_names = dataset.readline().split(',')\n",
    "    nan_col_names = [col_name for col_idx, col_name in enumerate(col_names[2:]) if nan_ratio[col_idx]]\n",
    "\n",
    "    print(\"Columns with > {:.2f} nan ratio :\".format(MAX_NAN_RATIO))\n",
    "    print(nan_col_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 6, sharex=False, sharey=False, figsize=(10, 6))\n",
    "\n",
    "# don't select nan values\n",
    "for col_idx in range(len(col_names)-2):\n",
    "    subplt = axs[col_idx%5, math.floor(col_idx/5)]\n",
    "\n",
    "    col = x_tr[:, col_idx]\n",
    "    subplt.hist(col[~np.isnan(col)], bins=20)\n",
    "    subplt.set_title(col_names[col_idx+2])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# fig.title(\"Histograms of raw features (exclude NAN values)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a feature\n",
    "col_name_to_plot = 'DER_pt_h'\n",
    "# col_names\n",
    "col_idx_to_plot = [col_idx-2 for col_idx, col_name in enumerate(col_names) if col_name_to_plot == col_name]\n",
    "\n",
    "col_to_plot = x_tr[:, col_idx_to_plot]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].hist(col_to_plot[~np.isnan(col_to_plot)], bins=20)\n",
    "axs[0].set_title(col_name_to_plot)\n",
    "\n",
    "col_nan = col_to_plot[~np.isnan(col_to_plot)]\n",
    "axs[1].boxplot(col_to_plot[~np.isnan(col_to_plot)])\n",
    "axs[1].set_title(col_name_to_plot)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(col_to_plot[~np.isnan(col_to_plot)])\n",
    "plt.title(col_name_to_plot + \"log log plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap\n",
    "# np.corrcoef(col_to_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering / Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic transformations\n",
    "- Remove features which contains too much NAN values, because they don't contain ennough information\n",
    "- Standardize training df\n",
    "- Replace missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with too much NAN\n",
    "# x_tr = x_tr[:, nan_ratio <= MAX_NAN_RATIO]\n",
    "# x_te = x_te[:, nan_ratio <= MAX_NAN_RATIO]\n",
    "\n",
    "print(\"x_tr shape : {}\".format(x_tr.shape))\n",
    "print(\"x_te shape : {}\".format(x_te.shape))\n",
    "\n",
    "# Standardize before replacing missing values\n",
    "x_tr, mean_x, std_x = standardize_training(x_tr, missing_values=True)\n",
    "x_te = standardize_test(x_te, mean_x, std_x)\n",
    "\n",
    "# Replace missing data by the mean\n",
    "x_tr = replace_nan_by_means(x_tr, mean_data=mean_x)\n",
    "x_te = replace_nan_by_means(x_te, mean_data=mean_x)\n",
    "\n",
    "assert(x_tr[np.isnan(x_tr)].shape[0] == 0)\n",
    "assert(x_te[np.isnan(x_te)].shape[0] == 0)\n",
    "\n",
    "print(\"x_tr range :{} {}\".format(np.nanmin(x_tr), np.nanmax(x_tr)))\n",
    "print(\"x_te range :{} {}\".format(np.nanmin(x_te), np.nanmax(x_te)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add offset term to x\n",
    "xt_tr = add_offset(x_tr)\n",
    "xt_te = add_offset(x_te)\n",
    "\n",
    "# Fit a model\n",
    "w, loss_tr = least_squares(y_tr, x_tr)\n",
    "loss_te = compute_mse(y_te, x_te, w)\n",
    "\n",
    "print(\"Training loss : {}\".format(loss_tr))\n",
    "print(\"Test loss : {}\".format(loss_te))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d6cc526fcb8a0758310ed89b8dab3b91f3ec4de7507d09c9bf6f1d1fde12f3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
